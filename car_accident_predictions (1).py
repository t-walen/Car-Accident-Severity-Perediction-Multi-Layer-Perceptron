# -*- coding: utf-8 -*-
"""Car Accident Predictions.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1HsDDuSTkKnkfGn5Oisbl4Ms0pTYAAYDv
"""

import pandas as pd

from google.colab import drive
drive.mount('/content/drive')

file_path = '/content/drive/My Drive/US_Accidents_March23.csv'
chunk_size = 100000


for chunk in pd.read_csv(file_path, chunksize=chunk_size):
    print(chunk.head())

print("Column Headers:", chunk.columns.tolist())


    print("First Row:\n", chunk.iloc[0])

state_counts = {}


for chunk in pd.read_csv(file_path, chunksize=chunk_size):

    chunk_counts = chunk['State'].value_counts()


    for state, count in chunk_counts.items():
        if state in state_counts:
            state_counts[state] += count
        else:
            state_counts[state] = count


state_counts_df = pd.DataFrame(list(state_counts.items()), columns=['State', 'Count']).sort_values(by='Count', ascending=False)


print(state_counts_df)

filtered_data = []


for chunk in pd.read_csv(file_path, chunksize=chunk_size):

  nj_chunk = chunk[chunk['State'] == 'NJ']

  filtered_data.append(nj_chunk)

nj_df = pd.concat(filtered_data, ignore_index=True)

print(nj_df.head())

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense
from tensorflow.keras.utils import to_categorical

#Data Preparation
missing_values_variables = nj_df[['Weather_Condition', 'Temperature(F)', "Wind_Chill(F)","Humidity(%)", "Pressure(in)", "Visibility(mi)", "Wind_Speed(mph)", "Precipitation(in)"]].isna().sum()

print(missing_values_variables)









nj_df = nj_df.drop(columns=['End_Lat', 'End_Lng', 'State', 'Country', 'Timezone', 'ID', 'Source'])

nj_df['Weather_Condition'] = nj_df['Weather_Condition'].fillna('Fair')

missing_values_rest = nj_df[['Start_Time', 'End_Time', "Distance(mi)","Description", "Zipcode", "Airport_Code", "Weather_Timestamp", "Wind_Direction", "Amenity", "Bump", "Crossing", "Give_Way", "Junction", "No_Exit", "Railway", "Roundabout", "Station", "Stop", "Traffic_Calming", "Traffic_Signal", "Turning_Loop", "Sunrise_Sunset", "Civil_Twilight", "Nautical_Twilight", "Astronomical_Twilight"]].isna().sum()

print(missing_values_rest)

most_common_airport_code = nj_df['Airport_Code'].mode()[0]
nj_df['Airport_Code'].fillna(most_common_airport_code, inplace=True)

nj_df['Weather_Timestamp'].fillna('12:00:00', inplace=True)


most_common_wind_direction = nj_df['Wind_Direction'].mode()[0]
nj_df['Wind_Direction'].fillna(most_common_wind_direction, inplace=True)


most_common_sunrise_sunset = nj_df['Sunrise_Sunset'].mode()[0]
nj_df['Sunrise_Sunset'].fillna(most_common_sunrise_sunset, inplace=True)


most_common_civil_twilight = nj_df['Civil_Twilight'].mode()[0]
nj_df['Civil_Twilight'].fillna(most_common_civil_twilight, inplace=True)


most_common_nautical_twilight = nj_df['Nautical_Twilight'].mode()[0]
nj_df['Nautical_Twilight'].fillna(most_common_nautical_twilight, inplace=True)


most_common_astronomical_twilight = nj_df['Astronomical_Twilight'].mode()[0]
nj_df['Astronomical_Twilight'].fillna(most_common_astronomical_twilight, inplace=True)

missing_values_all = nj_df.isna().sum()
missing_values_all

nj_df = nj_df.dropna(subset=['Street'])

nj_df = nj_df.dropna(subset=['Zipcode'])

missing_values_all = nj_df.isna().sum()
missing_values_all

X = nj_df.drop('Severity', axis=1)
y = nj_df['Severity']


categorical_cols = X.select_dtypes(include=['object']).columns
numerical_cols = X.select_dtypes(exclude=['object']).columns

from sklearn.preprocessing import StandardScaler
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.impute import SimpleImputer

preprocessor = ColumnTransformer(
    transformers=[
        ('num', Pipeline([
            ('imputer', SimpleImputer(strategy='mean')),
            ('scaler', StandardScaler())
        ]), numerical_cols),
    ])

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)


X_train = preprocessor.fit_transform(X_train)
X_test = preprocessor.transform(X_test)

from sklearn.neural_network import MLPClassifier
from sklearn.inspection import permutation_importance
from sklearn.metrics import accuracy_score


mlp = MLPClassifier(hidden_layer_sizes=(128, 64, 32), max_iter=1000, random_state=42)

mlp.fit(X_train, y_train)


y_pred = mlp.predict(X_test)
accuracy = accuracy_score(y_test, y_pred)
print(f"Test Accuracy: {accuracy * 100:.2f}%")

from sklearn.ensemble import RandomForestClassifier

rf = RandomForestClassifier(n_estimators=100, random_state=42)
rf.fit(X_train, y_train)
y_pred = rf.predict(X_test)

accuracy_RandomForest = accuracy_score(y_test, y_pred)
print(f"Test Accuracy: {accuracy_RandomForest * 100:.2f}%")